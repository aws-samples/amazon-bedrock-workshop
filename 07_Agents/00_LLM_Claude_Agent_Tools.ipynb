{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bedrock model integration with Langchain Agents\n",
    "\n",
    "Certain applications demand an adaptable sequence of calls to language models and various utilities depending on user input. The Agent interface enables such flexibility for these applications. An agent has availability to a range of resources and selects which ones to utilize based on the user input. Agents are capable of using multiple tools and utilizing the output of one tool as the input for the next.  \n",
    "\n",
    "There are two primary categories of agents:\n",
    "\n",
    "- Action agents: At each interval, determine the subsequent action utilizing the outputs of all previous actions. \n",
    "- Plan-and-execute agents: Determine the complete order of actions initially, then implement them all without updating the plan.\n",
    "\n",
    "In this notebook, we will demonstrate the use `plan-and-execute` agents along with `Zero-shot ReAct` which i an action agent and uses the [`ReAct`](https://arxiv.org/pdf/2205.00445.pdf) framework to select the appropriate tool based exclusively on the tool's description. It requires you provide the description of each tool. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "![](./images/arch-agents.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_parameter = {\"temperature\": 0.0, \"top_p\": .5, \"max_tokens_to_sample\": 2000}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ReAct: Synergizing Reasoning and Acting in Language Models Framework\n",
    "Large language models can generate both explanations for their reasoning and task-specific responses in an alternating fashion. \n",
    "\n",
    "Producing reasoning explanations enables the model to infer, monitor, and revise action plans, and even handle unexpected scenarios. The action step allows the model to interface with and obtain information from external sources such as knowledge bases or environments.\n",
    "\n",
    "The ReAct framework could enable large language models to interact with external tools to obtain additional information that results in more accurate and fact-based responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain import LLMMathChain\n",
    "from langchain.utilities import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from typing import Optional, List, Any\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "\n",
    "class BedrockModelWrapper(Bedrock):\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        prompt = \"\\n\\nHuman: \" + prompt + \"\\n\\nAssistant:\"   ## Satisfy Bedrock-Claude prompt requirements\n",
    "        return super()._call(prompt, stop, run_manager, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = BedrockModelWrapper(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock, model_kwargs=model_parameter)\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "react_agent = initialize_agent(tools, \n",
    "                               llm, \n",
    "                               agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                               verbose=True,\n",
    "                            #    max_iteration=2,\n",
    "                            #    return_intermediate_steps=True,\n",
    "                            #    handle_parsing_errors=True,\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do, Also try to follow steps mentioned above\n",
    "Action: the action to take, should be one of [\"serpapi\", \"llm-math\"]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Assistant:\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_agent.agent.llm_chain.prompt.template=prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Amazon SageMaker? What is the launch year multiplied by 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "react_agent(\"\\n\\nHuman:\" + question + \"\\n\\nAssistant:\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the tool code\n",
    "Could you use GenAI to author the code in the tools? Sure! With caution, there is some variation in the code and \n",
    "may not be safe for execution without a human review.\n",
    "\n",
    "The following example uses the code generated by Claude to generate the tool. It replaces the EC2Search tool above with the boto python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "prompt_data = \"\"\"\n",
    "Human: You are an AI python code generator. You write really great code.\n",
    "\n",
    "Write a python function named list_tagged_instances with one parameter named tagname. \n",
    "\n",
    "The function queries the boto3 library to return a list all of the EC2 instances that have a tag equal to the tagname parameter. \n",
    "\n",
    "return the code inside <code></code>.\n",
    "Assistant:\"\"\"\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-instant-v1\"  \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "tree = ET.ElementTree(ET.fromstring(response_body.get(\"completion\")))\n",
    "python_code = tree.getroot().text\n",
    "\n",
    "display(Markdown(f'```{python_code}```'))\n",
    "\n",
    "exec(python_code)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the code\n",
    "If the code above looks reasonable, we can use it to run our agent.\n",
    "\n",
    "**Note - for this to work, you need an EC2 instance in this account with a tag named 'delete' and any value in the tag. It is case senstitive, so prior to executing this, create an EC2 instance and set it to the stopped state.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tool in tools:\n",
    "    if tool.name == \"EC2Search\":\n",
    "        tool.func = list_tagged_instances\n",
    "        \n",
    "llm = BedrockModelWrapper(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock, model_kwargs=model_parameter)\n",
    "\n",
    "react_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "question = \"\"\"Human: Please list my EC2 instances with the a tag delete. \n",
    "Next, patch each of the instances and record the patch change record in the CMDB with a change type of 'PATCH'. \n",
    "Finally, for each of the instances stop the instance and tell me how many were stopped. \n",
    "Assistant:\"\"\"\n",
    "\n",
    "result = react_agent.run(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another variation - Search for an instance that does not exist\n",
    "The prompt changes to search for EC2 instances with a tag that does not exist, so no instances should be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"\"\"Human: Please list my EC2 instances with the a tag doesnotexist. \n",
    "Next, patch each of the instances and record the patch change record in the CMDB with a change type of 'PATCH'. \n",
    "Finally, for each of the instances stop the instance and tell me how many were stopped. \n",
    "Assistant:\"\"\"\n",
    "\n",
    "result = react_agent(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Tools\n",
    "A common use of an agent is to look up a record in a database. It would not be practical to include the full database in the context, so you can provide tools that perform actions against the datebase that eliminates hallucinations while maintining the conversational interactions.\n",
    "\n",
    "### SQL Database Agent\n",
    "Langachain has a SQL Database agent for demonstrating how to ask questions of a DB to get answers. For details, read this document: https://python.langchain.com/docs/integrations/toolkits/sql_database\n",
    "\n",
    "The agent will load the schema of the DB into context and generate SQL statements based on natural language questions. The SQL statement is then executed against the database and the results returned.\n",
    "\n",
    "### Data Agents\n",
    "While the SQL Database agent is useful for data exploration and generating queries, there are also cases where you want to \n",
    "For specific entities, a tool can be created to pull data from the database to provide context next steps in the prompt.\n",
    "\n",
    "The following example will simulate a DB query for a customer in the customer table. Replace this code with a lookup ib DynamoDB or a relation database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_table=[\n",
    "  {\n",
    "    \"id\": 1, \n",
    "    \"first_name\": \"John\", \n",
    "    \"last_name\": \"Doe\",\n",
    "    \"age\": 35,\n",
    "    \"postal_code\": \"90210\"\n",
    "  },\n",
    "  {  \n",
    "    \"id\": 2,\n",
    "    \"first_name\": \"Jane\",\n",
    "    \"last_name\": \"Smith\", \n",
    "    \"age\": 27,\n",
    "    \"postal_code\": \"12345\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 3, \n",
    "    \"first_name\": \"Bob\",\n",
    "    \"last_name\": \"Jones\",\n",
    "    \"age\": 42,\n",
    "    \"postal_code\": \"55555\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 4,\n",
    "    \"first_name\": \"Sara\", \n",
    "    \"last_name\": \"Miller\",\n",
    "    \"age\": 29, \n",
    "    \"postal_code\": \"13579\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 5,\n",
    "    \"first_name\": \"Mark\",\n",
    "    \"last_name\": \"Davis\",\n",
    "    \"age\": 31,\n",
    "    \"postal_code\": \"02468\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 6,\n",
    "    \"first_name\": \"Laura\",\n",
    "    \"last_name\": \"Wilson\",\n",
    "    \"age\": 24,\n",
    "    \"postal_code\": \"98765\" \n",
    "  },\n",
    "  {\n",
    "    \"id\": 7,\n",
    "    \"first_name\": \"Steve\",\n",
    "    \"last_name\": \"Moore\",\n",
    "    \"age\": 36,\n",
    "    \"postal_code\": \"11223\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 8,\n",
    "    \"first_name\": \"Michelle\",\n",
    "    \"last_name\": \"Chen\",\n",
    "    \"age\": 22,\n",
    "    \"orders\": [\n",
    "        {\n",
    "            \"order_id\": 1,\n",
    "            \"description\": \"An order of 1 dozen pencils\"\n",
    "        },\n",
    "        {\n",
    "            \"order_id\": 2,\n",
    "            \"description\": \"An order of 2 markers\"\n",
    "        }\n",
    "    ],\n",
    "    \"postal_code\": \"33215\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 9,\n",
    "    \"first_name\": \"David\",\n",
    "    \"last_name\": \"Lee\",\n",
    "    \"age\": 29,\n",
    "    \"postal_code\": \"99567\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 10,\n",
    "    \"first_name\": \"Jessica\",\n",
    "    \"last_name\": \"Brown\",\n",
    "    \"age\": 18, \n",
    "    \"postal_code\": \"43210\"\n",
    "  }\n",
    "]\n",
    "\n",
    "def customer_lookup(id):\n",
    "    print(f\"search by customer {id}\")\n",
    "    for customer in customer_table:\n",
    "        if customer[\"id\"] == int(id):\n",
    "            print(f\"found customer {id} {customer}\")\n",
    "            return customer\n",
    "        \n",
    "    return None\n",
    "\n",
    "tools.append(Tool.from_function(\n",
    "        name=\"CustomerLookup\",\n",
    "        func=customer_lookup,  # Mock Function, replace with an api call\n",
    "        description=\"Use this when you need to lookup a customer by id.\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "react_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "question = \"\"\"\\n\\nHuman: write one sentence summary about the information you know about the customer with an id of 2.\n",
    "\n",
    "\\n\\nAssistant: Here is the one sentence summary: \"\"\"\n",
    "\n",
    "result = react_agent.run(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
