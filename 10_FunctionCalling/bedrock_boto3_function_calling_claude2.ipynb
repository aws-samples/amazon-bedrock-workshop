{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a5ab2f-d044-4956-b75b-7408d9c3e323",
   "metadata": {},
   "source": [
    "# Amazon Bedrock boto3 Setup\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio. You can also run on a local setup, as long as you have the right IAM credentials to invoke the Claude model via Bedrock*\n",
    "\n",
    "---\n",
    "\n",
    "In this demo notebook, we demonstrate an implementation of Function Calling with Anthropic's Claude models via Bedrock. This notebook is inspired by the [original work](https://drive.google.com/drive/folders/1-94Fa3HxEMkxkwKppe8lp_9-IXXvsvv1) by the Anthropic Team and modified it for use with Amazon Bedrock.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeedd9f-f0a3-4f8e-934d-22f6f7a89de5",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Run the cells in this section to install the needed packages for workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c611c-7246-45c4-9f1e-76888b5076eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\" \\\n",
    "    \"requests\" \\\n",
    "    \"defusedxml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27610c0f-7de6-4440-8f76-decf30e3c5ca",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "⚠️ ⚠️ ⚠️ Before running this notebook, ensure you've run the [Bedrock boto3 setup notebook](../00_Intro/bedrock_boto3_setup.ipynb#Prerequisites) notebook. ⚠️ ⚠️ ⚠️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae2b2a05-78a9-40ca-9b5e-121030f9ede1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "\n",
    "bedrock_runtime = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb6bee-7654-4269-9127-9afa4e823454",
   "metadata": {},
   "source": [
    "### Anthropic Claude\n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"\\n\\nHuman:<prompt>\\n\\nAnswer:\",\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"completion\": \"<output>\",\n",
    "    \"stop_reason\": \"stop_sequence\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c0fe6-576a-4380-89aa-726bab5d65ff",
   "metadata": {},
   "source": [
    "### Anthropic Claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeff818",
   "metadata": {},
   "source": [
    "The crux of this example is to let Claude models know about a set of `tools` that it has available i.e. functions it can call between a set of tags. This is possible because Anthropic's Claude models have been extensively trainied on such tags in its training corpus.\n",
    "\n",
    "Then present a way to call the tools in a step by step fashion till it gets the right answer. We create a set of callable functions in another file called `tools.py`\n",
    "\n",
    "A sample `tools.py` is added to the same folder of this notebook and can be modified to suit your needs. Once you have modified `tools.py`, import it so that we have access to it in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337d75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb60ff51",
   "metadata": {},
   "source": [
    "We then create a set of auxillary functions that help create the input prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0ffb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(tools_string, user_input):\n",
    "    prompt_template = f\"\"\"\n",
    "In this environment you have access to a set of tools you can use to answer the user's question.\n",
    "\n",
    "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
    "<function_calls>\n",
    "<invoke>\n",
    "<tool_name>$TOOL_NAME</tool_name>\n",
    "<parameters>\n",
    "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
    "...\n",
    "</parameters>\n",
    "</invoke>\n",
    "</function_calls>\n",
    "\n",
    "Here are the tools available:\n",
    "<tools>\n",
    "{tools_string}\n",
    "</tools>\n",
    "\n",
    "Human:\n",
    "{user_input}\n",
    "\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "177591b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tools():\n",
    "    tools_string = \"\"\n",
    "    for tool_spec in tools.list_of_tools_specs:\n",
    "        tools_string += tool_spec\n",
    "    return tools_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a53483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from defusedxml import ElementTree\n",
    "from collections import defaultdict\n",
    "# print(add_tools())\n",
    "# Uncomment print to test if tools is being imported correctly and your functions are correctly being interpreted via the tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c376be",
   "metadata": {},
   "source": [
    "This `call_function` will be used later to extract the name of the tool from your `tools.py` file and call it from the output of Claude. A few more helper functions are defined and can be used as is without modification for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff4955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(tool_name, parameters):\n",
    "    func = getattr(tools, tool_name)\n",
    "    output = func(**parameters)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e52339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_result(tool_name, output):\n",
    "    return f\"\"\"\n",
    "<function_results>\n",
    "<result>\n",
    "<tool_name>{tool_name}</tool_name>\n",
    "<stdout>\n",
    "{output}\n",
    "</stdout>\n",
    "</result>\n",
    "</function_results>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3112c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etree_to_dict(t) -> dict[str, Any]:\n",
    "    d = {t.tag: {}}\n",
    "    children = list(t)\n",
    "    if children:\n",
    "        dd = defaultdict(list)\n",
    "        for dc in map(etree_to_dict, children):\n",
    "            for k, v in dc.items():\n",
    "                dd[k].append(v)\n",
    "        d = {t.tag: {k: v[0] if len(v) == 1 else v for k, v in dd.items()}}\n",
    "    if t.attrib:\n",
    "        d[t.tag].update((\"@\" + k, v) for k, v in t.attrib.items())\n",
    "    if t.text and t.text.strip():\n",
    "        if children or t.attrib:\n",
    "            d[t.tag][\"#text\"] = t.text\n",
    "        else:\n",
    "            d[t.tag] = t.text\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e4062d",
   "metadata": {},
   "source": [
    "Here is where we can glue all the pieces together. Print the final prompt data to double check if the input is you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c613eef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this environment you have access to a set of tools you can use to answer the user's question.\n",
      "\n",
      "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>$TOOL_NAME</tool_name>\n",
      "<parameters>\n",
      "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
      "...\n",
      "</parameters>\n",
      "</invoke>\n",
      "</function_calls>\n",
      "\n",
      "Here are the tools available:\n",
      "<tools>\n",
      "\n",
      "<tool_description>\n",
      "<tool_name>get_weather</tool_name>\n",
      "<description>\n",
      "Returns weather data for a given latitude and longitude. </description>\n",
      "<parameters>\n",
      "<parameter>\n",
      "<name>latitude</name>\n",
      "<type>string</type>\n",
      "<description>The latitude coordinate as a string</description>\n",
      "</parameter> <parameter>\n",
      "<name>longitude</name>\n",
      "<type>string</type>\n",
      "<description>The longitude coordinate as a string</description>\n",
      "</parameter>\n",
      "</parameters>\n",
      "</tool_description>\n",
      "<tool_description>\n",
      "<tool_name>get_lat_long</tool_name>\n",
      "<description>\n",
      "Returns the latitude and longitude for a given place name.\n",
      "</description>\n",
      "<parameters>\n",
      "<parameter>\n",
      "<name>place</name>  \n",
      "<type>string</type>\n",
      "<description>\n",
      "The place name to geocode and get coordinates for.\n",
      "</description>\n",
      "</parameter>\n",
      "</parameters>\n",
      "</tool_description>\n",
      "</tools>\n",
      "\n",
      "Human:\n",
      "Can you check the weather for me in San Francisco?\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you check the weather for me in San Francisco?\"\n",
    "tools_string = add_tools()\n",
    "prompt_data = create_prompt(tools_string, user_input)\n",
    "print(prompt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe6dab",
   "metadata": {},
   "source": [
    "This next cell is to test the response of the Claude models based on your constructed input. Note that we have not instrumented output to call the actual functions, but this should give you an idea on how Claude's output can be parsed and the corresponding functions can be subsequently called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c78100e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is how I can check the weather in San Francisco:\n",
      "\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>get_lat_long</tool_name>  \n",
      "<parameters>\n",
      "<place>San Francisco</place>\n",
      "</parameters>\n",
      "</invoke>\n",
      "</function_calls>\n",
      "\n",
      "This will first get the latitude and longitude coordinates for San Francisco. \n",
      "\n",
      "Then I can pass those coordinates to the get_weather tool:\n",
      "\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>get_weather</tool_name>\n",
      "<parameters>\n",
      "<latitude>37.7749</latitude>\n",
      "<longitude>-122.4194</longitude>  \n",
      "</parameters>\n",
      "</invoke> \n",
      "</function_calls>\n",
      "\n",
      "This will retrieve the current weather data for those coordinates, giving us the weather in San Francisco.\n",
      "\n",
      "Let me know if you need me to actually call the tools and get the weather report!\n"
     ]
    }
   ],
   "source": [
    "body = json.dumps({\"prompt\": prompt_data, \n",
    "                   \"max_tokens_to_sample\": 1000,\n",
    "                   \"temperature\": 0,\n",
    "                   \"stop_sequences\": [\"\\n\\nHuman:\"]})\n",
    "# modelId = \"anthropic.claude-instant-v1\"  # change this to use a different version from the model provider\n",
    "modelId = \"anthropic.claude-v2\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    print(response_body.get(\"completion\"))\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    \n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d60eb1c",
   "metadata": {},
   "source": [
    "### Run loop\n",
    "\n",
    "This function is the actual orchestrator of the function calling logic. Here's how it works:\n",
    "\n",
    "1. We kick off a loop that first calls Claude with our tool use prompt with the tool specs and the user input loaded into it.\n",
    "2. We get the completion from Claude and check if the stop sequence for the completion was the closing tag for a function call, ```</function_calls>```\n",
    "3. If the completion does in fact contain a function call, we extract out the tool name and the tool parameters from the tags.\n",
    "4. We then call the function that Claude has decided to invoke using our helped auxillary function.\n",
    "5. We take the results of the function call, format them into an tag structure, and add them back to the prompt. This works because with subsequent calls, we are basically pre-filling the output of the model and asking it to pick up where it left off, with addition data from the previous results.\n",
    "6. We repeat the loop starting at step 1 with the original prompt plus the text that has been appended.\n",
    "7. This process continues until Claude finally outputs an answer and we break the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "262dd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loop(prompt):\n",
    "    print(prompt)\n",
    "    # Start function calling loop\n",
    "    while True:\n",
    "        body = json.dumps({\"prompt\": prompt, \n",
    "                   \"max_tokens_to_sample\": 1000,\n",
    "                   \"temperature\": 0,\n",
    "                   \"stop_sequences\": [\"\\n\\nHuman:\", \"</function_calls>\"]})\n",
    "        # modelId = \"anthropic.claude-instant-v1\"  # change this to use a different version from the model provider\n",
    "        modelId = \"anthropic.claude-v2\"  # change this to use a different version from the model provider\n",
    "        accept = \"application/json\"\n",
    "        contentType = \"application/json\"\n",
    "\n",
    "        # Get a completion from Claude\n",
    "        try:\n",
    "            response = bedrock_runtime.invoke_model(\n",
    "                body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "            )\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "            partial_completion = response_body.get(\"completion\")\n",
    "            stop_reason = response_body.get(\"stop_reason\") \n",
    "        except botocore.exceptions.ClientError as error:\n",
    "            if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "                print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                        \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                        \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "            else:\n",
    "                raise error\n",
    "\n",
    "        # Append the completion to the end of the prommpt\n",
    "        prompt += partial_completion\n",
    "        if stop_reason == 'stop_sequence':\n",
    "            # If Claude made a function call\n",
    "            print(partial_completion)\n",
    "            start_index = partial_completion.find(\"<function_calls>\")\n",
    "\n",
    "            if start_index != -1:\n",
    "                # Extract the XML Claude outputted (invoking the function)\n",
    "                extracted_text = partial_completion[start_index+16:]\n",
    "\n",
    "                # Parse the XML find the tool name and the parameters that we need to pass to the tool\n",
    "                xml = ElementTree.fromstring(extracted_text)\n",
    "                tool_name_element = xml.find(\"tool_name\")\n",
    "                if tool_name_element is None:\n",
    "                    print(\"Unable to parse function call, invalid XML or missing 'tool_name' tag\")\n",
    "                    break\n",
    "                tool_name_from_xml = tool_name_element.text.strip()\n",
    "                parameters_xml = xml.find(\"parameters\")\n",
    "                if parameters_xml is None:\n",
    "                    print(\"Unable to parse function call, invalid XML or missing 'parameters' tag\")\n",
    "                    break\n",
    "                param_dict = etree_to_dict(parameters_xml)\n",
    "                parameters = param_dict[\"parameters\"]\n",
    "\n",
    "                # Call the tool we defined in tools.py\n",
    "                output = call_function(tool_name_from_xml, parameters)\n",
    "\n",
    "                # Add the stop sequence back to the prompt\n",
    "                prompt += \"</function_calls>\"\n",
    "                print(\"</function_calls> -- appending\")\n",
    "\n",
    "                # Add the result from calling the tool back to the prompt\n",
    "                function_result = format_result(tool_name_from_xml, output)\n",
    "                print(function_result)\n",
    "                prompt += function_result\n",
    "            else: # Once the output of the prompt does not have the <function_calls>, the start_index will be = -1, which means no more functions to be called. \n",
    "                break\n",
    "        else:\n",
    "            # If Claude did not make a function call\n",
    "            # outputted answer\n",
    "            print(partial_completion)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b234d381",
   "metadata": {},
   "source": [
    "Let's run it all together now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c2bee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this environment you have access to a set of tools you can use to answer the user's question.\n",
      "\n",
      "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>$TOOL_NAME</tool_name>\n",
      "<parameters>\n",
      "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
      "...\n",
      "</parameters>\n",
      "</invoke>\n",
      "</function_calls>\n",
      "\n",
      "Here are the tools available:\n",
      "<tools>\n",
      "\n",
      "<tool_description>\n",
      "<tool_name>get_weather</tool_name>\n",
      "<description>\n",
      "Returns weather data for a given latitude and longitude. </description>\n",
      "<parameters>\n",
      "<parameter>\n",
      "<name>latitude</name>\n",
      "<type>string</type>\n",
      "<description>The latitude coordinate as a string</description>\n",
      "</parameter> <parameter>\n",
      "<name>longitude</name>\n",
      "<type>string</type>\n",
      "<description>The longitude coordinate as a string</description>\n",
      "</parameter>\n",
      "</parameters>\n",
      "</tool_description>\n",
      "<tool_description>\n",
      "<tool_name>get_lat_long</tool_name>\n",
      "<description>\n",
      "Returns the latitude and longitude for a given place name.\n",
      "</description>\n",
      "<parameters>\n",
      "<parameter>\n",
      "<name>place</name>  \n",
      "<type>string</type>\n",
      "<description>\n",
      "The place name to geocode and get coordinates for.\n",
      "</description>\n",
      "</parameter>\n",
      "</parameters>\n",
      "</tool_description>\n",
      "</tools>\n",
      "\n",
      "Human:\n",
      "Can you check the weather for me in San Francisco?\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      " Here is how I can check the weather in San Francisco:\n",
      "\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>get_lat_long</tool_name>  \n",
      "<parameters>\n",
      "<place>San Francisco</place>\n",
      "</parameters>\n",
      "</invoke>\n",
      "\n",
      "</function_calls> -- appending\n",
      "\n",
      "<function_results>\n",
      "<result>\n",
      "<tool_name>get_lat_long</tool_name>\n",
      "<stdout>\n",
      "{'latitude': '37.7790262', 'longitude': '-122.419906'}\n",
      "</stdout>\n",
      "</result>\n",
      "</function_results>\n",
      "\n",
      "\n",
      "This gets the latitude and longitude coordinates for San Francisco. Then I can pass those coordinates to get the weather:\n",
      "\n",
      "<function_calls>  \n",
      "<invoke>\n",
      "<tool_name>get_weather</tool_name>\n",
      "<parameters>\n",
      "<latitude>37.7790262</latitude>\n",
      "<longitude>-122.419906</longitude>\n",
      "</parameters>\n",
      "</invoke>\n",
      "\n",
      "</function_calls> -- appending\n",
      "\n",
      "<function_results>\n",
      "<result>\n",
      "<tool_name>get_weather</tool_name>\n",
      "<stdout>\n",
      "{'latitude': 37.78929, 'longitude': -122.422, 'generationtime_ms': 0.06699562072753906, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 19.0, 'current_weather_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature': '°C', 'windspeed': 'km/h', 'winddirection': '°', 'is_day': '', 'weathercode': 'wmo code'}, 'current_weather': {'time': '2023-10-20T00:30', 'interval': 900, 'temperature': 22.2, 'windspeed': 20.6, 'winddirection': 264, 'is_day': 1, 'weathercode': 0}}\n",
      "</stdout>\n",
      "</result>\n",
      "</function_results>\n",
      "\n",
      "\n",
      "So the current weather in San Francisco is 22.2°C with wind speeds of 20.6 km/h from the west. Let me know if you need any other weather details!\n"
     ]
    }
   ],
   "source": [
    "run_loop(prompt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48a0e8-147d-4525-a6b2-68a09af1b2c4",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "In this notebook we showed some basic examples of invoking Amazon Bedrock models using the AWS Python SDK. You're now ready to explore the other labs to dive deeper on different use-cases and patterns."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
