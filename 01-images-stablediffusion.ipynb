{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating images using Stable Diffusion\n",
    "\n",
    "> This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio and with the **`conda_python3`** in a SageMaker Notebook Instance.\n",
    "\n",
    "---\n",
    "\n",
    "In this demo notebook, we show how to use [Stable Diffusion XL](https://stability.ai/stablediffusion) (SDXL) on [Amazon Bedrock](https://aws.amazon.com/bedrock/) for image generation (text-to-image) and image editing (image-to-image).\n",
    "\n",
    "Images in Stable Diffusion are generated by these 4 main models below\n",
    "1. The CLIP text encoder;\n",
    "2. The VAE decoder;\n",
    "3. The UNet, and\n",
    "4. The VAE_post_quant_conv\n",
    "\n",
    "These blocks are chosen because they represent the bulk of the compute in the pipeline\n",
    "\n",
    "see this diagram below\n",
    "\n",
    "![SD Architecture](./images/sd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image prompting\n",
    "\n",
    "Writing a good prompt can be somewhat of an art. It's often difficult to predict whether a certain prompt will yield a satisfactory image with a given model. However, there are certain templates that have been observed to work. Broadly, a prompt can be roughly broken down into three pieces:\n",
    "\n",
    "1. **Type** of image (photograph/sketch/painting etc.)\n",
    "2. **Description** of the content (subject/object/environment/scene etc.), and\n",
    "3. **Style** of the image (realistic/artistic/type of art etc.).\n",
    "\n",
    "You can change each of the three parts individually to generate variations of an image. Adjectives have been known to play a significant role in the image generation process. Also, adding more details help in the generation process.\n",
    "\n",
    "To generate a realistic image, you can use phrases such as “a photo of”, “a photograph of”, “realistic” or “hyper realistic”. To generate images by artists you can use phrases like “by Pablo Piccaso” or “oil painting by Rembrandt” or “landscape art by Frederic Edwin Church” or “pencil drawing by Albrecht Dürer”. You can also combine different artists as well. To generate artistic image by category, you can add the art category in the prompt such as “lion on a beach, abstract”. Some other categories include “oil painting”, “pencil drawing, “pop art”, “digital art”, “anime”, “cartoon”, “futurism”, “watercolor”, “manga” etc. You can also include details such as lighting or camera lens such as 35mm wide lens or 85mm wide lens and details about the framing (portrait/landscape/close up etc.).\n",
    "\n",
    "Note that model generates different images even if same prompt is given multiple times. So, you can generate multiple images and select the image that suits your application best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# External dependencies\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import botocore\n",
    "from PIL import ImageOps\n",
    "\n",
    "boto3_bedrock = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Image\n",
    "\n",
    "In text-to-image mode, we'll provide a text description of what image **should** be generated, called a `prompt`.\n",
    "\n",
    "With Stable Diffusion XL (SDXL) we can also specify certain [style presets](https://platform.stability.ai/docs/release-notes#style-presets) to help influence the generation.\n",
    "\n",
    "To further influence image generation, we make use of [clip guidance presets](https://platform.stability.ai/docs/features/api-parameters#clip_guidance) and [samplers](https://platform.stability.ai/docs/features/api-parameters#sampler) to get more desirable results. \n",
    "\n",
    "Although the current SDXL model defaults to a square [resolution](https://platform.stability.ai/docs/features/api-parameters#about-dimensions) of 512px x 512px, it is capable of generating images at higher resolutions and non-squared aspect ratios. As shown below, the `width` of the image was set to 768px and the `height` remains at its default value of 512px. \n",
    "\n",
    "But what if we want to nudge the model to ***avoid*** specific content or style choices? Because image generation models are typically trained from *image descriptions*, trying to directly specify what you **don't** want in the prompt (for example `man without a beard`) doesn't usually work well: It would be very unusual to describe an image by the things it isn't!\n",
    "\n",
    "Instead, SDXL lets us specify a `weight` for each prompt, which can be negative. We'll use this to provide `negative_prompts` as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amazon Bedrock `InvokeModel` provides access to SDXL by setting the right model ID, and returns a JSON response including a [Base64 encoded string](https://en.wikipedia.org/wiki/Base64) that represents the (PNG) image.\n",
    "\n",
    "For more information on available input parameters for the model, refer to the [Stability AI docs](https://platform.stability.ai/docs/api-reference#tag/v1generation/operation/textToImage).\n",
    "\n",
    "The cell below invokes the SDXL model through Amazon Bedrock to create an initial image string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prompts_list = [\n",
    "    \"out of frame\",\n",
    "    \"lowres\",\n",
    "    \"text\",\n",
    "    \"error\",\n",
    "    \"cropped\",\n",
    "    \"worst quality\",\n",
    "    \"low quality\",\n",
    "    \"jpeg artifacts\",\n",
    "    \"ugly\",\n",
    "    \"duplicate\",\n",
    "    \"out of frame\",\n",
    "    \"extra fingers\",\n",
    "    \"mutated hands\",\n",
    "    \"poorly drawn hands\",\n",
    "    \"poorly drawn face\",\n",
    "    \"mutation\",\n",
    "    \"deformed\",\n",
    "    \"blurry\",\n",
    "    \"dehydrated\",\n",
    "    \"bad anatomy\",\n",
    "    \"bad proportions\",\n",
    "    \"extra limbs\",\n",
    "    \"cloned face\",\n",
    "    \"disfigured\",\n",
    "    \"gross proportions\",\n",
    "    \"malformed limbs\",\n",
    "    \"missing arms\",\n",
    "    \"missing legs\",\n",
    "    \"extra arms\",\n",
    "    \"extra legs\",\n",
    "    \"fused fingers\",\n",
    "    \"too many fingers\",\n",
    "    \"long neck\",\n",
    "    \"username\",\n",
    "    \"watermark\",\n",
    "    \"signature\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a beautiful mountain landscape\"\n",
    "style_preset = \"photographic\" # (3d-model analog-film anime cinematic comic-book digital-art enhance fantasy-art isometric line-art low-poly modeling-compound neon-punk origami photographic pixel-art tile-texture)\n",
    "\n",
    "cfg_scale = 5  # How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt), [0, 35], default 7\n",
    "seed = 42\n",
    "n_steps = 60  # The number of steps for the diffusion process, [10, 150], default 30\n",
    "width = 768  # multiple of 64 >= 128 default 512\n",
    "clip_guidance_preset = (\n",
    "    \"FAST_GREEN\"   # (\"SLOWEST\",  \"FAST_BLUE\",\"FAST_GREEN\",\"NONE\",\"SIMPLE\",\"SLOW\",\"SLOWER\",\"SLOWEST\",]\n",
    ")\n",
    "sampler = \"K_DPMPP_2S_ANCESTRAL\"  # (DDIM DDPM K_DPMPP_2M K_DPMPP_2S_ANCESTRAL K_DPM_2 K_DPM_2_ANCESTRAL K_EULER K_EULER_ANCESTRAL K_HEUN K_LMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt, \"weight\": 1.0}]\n",
    "        + [{\"text\": negprompt, \"weight\": -1.0} for negprompt in negative_prompts_list]\n",
    "    ),\n",
    "    \"cfg_scale\": cfg_scale, \n",
    "    \"seed\": seed,\n",
    "    \"steps\": n_steps,\n",
    "    \"style_preset\": style_preset,\n",
    "    \"clip_guidance_preset\": clip_guidance_preset,\n",
    "    \"sampler\": sampler,\n",
    "    \"width\": width,\n",
    "    \"cfg_scale\": cfg_scale,\n",
    "    \n",
    "})\n",
    "modelId = \"stability.stable-diffusion-xl-v1\"\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{base_64_img_str[0:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By decoding our Base64 string to binary, and loading it with an image processing library like [Pillow](https://pillow.readthedocs.io/en/stable/) that can read PNG files, we can display and manipulate the image here in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "image_1 = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "image_1.save(\"data/image_1.png\")\n",
    "image_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to Image\n",
    "\n",
    "Generating images from text is powerful, but in some cases could need many rounds of prompt refinement to get an image \"just right\".\n",
    "\n",
    "Rather than starting from scratch with text each time, image-to-image generation lets us **modify an existing image** to make the specific changes we'd like.\n",
    "\n",
    "We'll have to pass our initial image in to the API in base64 encoding, so first let's prepare that. You can use either the initial image from the previous section, or a different one if you'd prefer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_base64(img) -> str:\n",
    "    \"\"\"Convert a PIL Image or local image file path to a base64 string for Amazon Bedrock\"\"\"\n",
    "    if isinstance(img, str):\n",
    "        if os.path.isfile(img):\n",
    "            print(f\"Reading image from file: {img}\")\n",
    "            with open(img, \"rb\") as f:\n",
    "                return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"File {img} does not exist\")\n",
    "    elif isinstance(img, Image.Image):\n",
    "        print(\"Converting PIL Image to base64 string\")\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"PNG\")\n",
    "        return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(f\"Expected str (filename) or PIL Image. Got {type(img)}\")\n",
    "\n",
    "\n",
    "init_image_b64 = image_to_base64(image_1)\n",
    "print(init_image_b64[:80] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new guiding prompt can then help the model to act on the intial image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "change_prompt = \"add denser number of trees, extend lake\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The existing image is then passed through to the Stable Diffusion model via the `init_image` parameter.\n",
    "\n",
    "Again, you can refer to the [Stable Diffusion API docs](https://platform.stability.ai/docs/api-reference#tag/v1generation/operation/imageToImage) for more tips on how to use the different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": change_prompt, \"weight\": 1.0}]\n",
    "        + [{\"text\": negprompt, \"weight\": -1.0} for negprompt in negative_prompts_list]\n",
    "    ),\n",
    "    \"cfg_scale\": 10,\n",
    "    \"init_image\": init_image_b64,\n",
    "    \"seed\": 321,\n",
    "    \"start_schedule\": 0.6,\n",
    "    \"steps\": 50,\n",
    "    \"style_preset\": style_preset,\n",
    "    \"clip_guidance_preset\": clip_guidance_preset,\n",
    "    \"sampler\": sampler,\n",
    "})\n",
    "modelId = \"stability.stable-diffusion-xl-v1\"\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "image_2_b64_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{image_2_b64_str[0:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_2 = Image.open(io.BytesIO(base64.decodebytes(bytes(image_2_b64_str, \"utf-8\"))))\n",
    "image_2.save(\"data/image_2.png\")\n",
    "image_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Inpainting\n",
    "\n",
    "Yet another alternative to modify images is by using \"inpainting\". Inpainting refers to the process of replacing a portion of an image with another image based on a textual prompt. By providing a mask image that outlines the portion to be replaced, a textual prompt, and an image, the Stable Diffusion model can produce a new image that replaces the masked area with the object, subject, or environment described in the textual prompt.\n",
    "\n",
    "You can use the mask provided in the `images/mask.png` file.\n",
    "\n",
    "**Note**: The mask image is required to be the same resolution and aspect ratio as the image being inpainted upon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inpaint_mask(img, box):\n",
    "    \"\"\"Generates a segmentation mask for inpainting\"\"\"\n",
    "    img_size = img.size\n",
    "    assert len(box) == 4  # (left, top, right, bottom)\n",
    "    assert box[0] < box[2]\n",
    "    assert box[1] < box[3]\n",
    "    return ImageOps.expand(\n",
    "        Image.new(\n",
    "            mode = \"RGB\",\n",
    "            size = (\n",
    "                box[2] - box[0],\n",
    "                box[3] - box[1]\n",
    "            ),\n",
    "            color = 'black'\n",
    "        ),\n",
    "        border=(\n",
    "            box[0],\n",
    "            box[1],\n",
    "            img_size[0] - box[2],\n",
    "            img_size[1] - box[3]\n",
    "        ),\n",
    "        fill='white'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img2_size = image_2.size\n",
    "box = (\n",
    "        (0),\n",
    "        (img2_size[1] - 900) ,\n",
    "        (img2_size[0]),\n",
    "        img2_size[1] - 700\n",
    "    )\n",
    "\n",
    "# Mask\n",
    "mask = inpaint_mask(\n",
    "    image_2,\n",
    "    box\n",
    ")\n",
    "\n",
    "# Debug\n",
    "# mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define what we want to change in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inpaint_prompt = \"add a helicopter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to what we did before, we will the pass the previously generated image through to the Stable Diffusion model via the `init_image` parameter.\n",
    "\n",
    "This time, we will also specify the `mask_source` parameter to pass the mask. \n",
    "\n",
    "You can refer to the [Stable Diffusion API docs](https://platform.stability.ai/docs/api-reference#tag/v1generation/operation/imageToImage) for more tips on how to use the different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\":[{\"text\": inpaint_prompt}],\n",
    "    \"init_image\": image_to_base64(image_2),\n",
    "    \"mask_source\": \"MASK_IMAGE_BLACK\",\n",
    "    \"mask_image\": image_to_base64(mask),\n",
    "    \"cfg_scale\": 10,\n",
    "    \"seed\": 32123,\n",
    "    \"style_preset\": style_preset,\n",
    "})\n",
    "modelId = \"stability.stable-diffusion-xl-v1\"\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "image_3_b64_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{image_2_b64_str[0:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets show the image we just modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "inpaint = Image.open(io.BytesIO(base64.decodebytes(bytes(image_3_b64_str, \"utf-8\"))))\n",
    "inpaint.save(\"data/inpaint.png\")\n",
    "inpaint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab we demonstrated how to generate new images from text, and transform existing images with text instructions - using [Stable Diffusion XL](https://stability.ai/stablediffusion) on [Amazon Bedrock](https://aws.amazon.com/bedrock/).\n",
    "\n",
    "Through the Bedrock API, we can provide a range of parameters to influence image generation which generally correspond to those listed in the [Stable Diffusion API docs](https://platform.stability.ai/docs/api-reference#tag/v1generation).\n",
    "\n",
    "One key point to note when using Bedrock is that output image PNG/JPEG data is returned as a [Base64 encoded string](https://en.wikipedia.org/wiki/Base64) within the JSON API response: You can use the Python built-in [base64 library](https://docs.python.org/3/library/base64.html) to decode this image data - for example to save a `.png` file. We also showed that image processing libraries like [Pillow](https://pillow.readthedocs.io/en/stable/) can be used to load (and perhaps edit) the images within Python.\n",
    "\n",
    "From here you can explore more advanced image generation options - or combine GenAI with traditional image processing tools - to build the best creative workflow for your use-case."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "langchain_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 50,
           "length": 1,
           "op": "removerange"
          },
          {
           "key": 52,
           "op": "addrange",
           "valuelist": "a"
          },
          {
           "key": 55,
           "op": "addrange",
           "valuelist": "1:0813"
          },
          {
           "key": 56,
           "op": "addrange",
           "valuelist": "5"
          },
          {
           "key": 56,
           "length": 2,
           "op": "removerange"
          },
          {
           "key": 59,
           "op": "addrange",
           "valuelist": "90"
          },
          {
           "key": 59,
           "length": 2,
           "op": "removerange"
          },
          {
           "key": 62,
           "op": "addrange",
           "valuelist": "99"
          },
          {
           "key": 62,
           "length": 7,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
