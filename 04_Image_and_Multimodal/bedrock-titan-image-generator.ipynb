{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating images using Amazon Titan Image Generator\n",
    "\n",
    "> ☝️ This notebook should work well with the **`Data Science 3.0`** kernel in Amazon SageMaker Studio and with the **`conda_python3`** in a Amazon SageMaker Notebook Instance.\n",
    "\n",
    "---\n",
    "\n",
    "In this tutorial, we will show how to use the new [Amazon Titan Image Generator](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-image-models.html) on [Amazon Bedrock](https://aws.amazon.com/bedrock/) model to generate (text-to-image) and edit (image-to-image) images.\n",
    "\n",
    "![](images/titan_image_generator_playground.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Image Prompting\n",
    "\n",
    "Writing a good prompt can be somewhat of an art.\n",
    "\n",
    "It is often difficult to predict whether a given prompt will yield a satisfactory result with a certain model. \n",
    "\n",
    "However, there are certain templates that have been known to work.\n",
    "\n",
    "Broadly, a prompt can be broken down into three pieces:\n",
    "\n",
    "1. **Type** of image (photograph/sketch/painting/&c.)\n",
    "2. **Description** of the content (subject/object/environment/scene/&c.), and\n",
    "3. **Style** of the image (realistic/artistic/&c.).\n",
    "\n",
    "You can change each of the three parts individually to generate variations of an image. \n",
    "\n",
    "Adjectives have been known to play a significant role in the image generation process. \n",
    "\n",
    "Also, adding more details help in the generation process.\n",
    "\n",
    "In order to generate a **realistic** image, you can use phrases such as\n",
    "\n",
    "```\n",
    "a photo of\n",
    "a photograph of\n",
    "realistic\n",
    "hyper realistic\n",
    "```\n",
    "\n",
    "To generate something more **artistic**, you can use phrases like\n",
    "\n",
    "```\n",
    "by Pablo Picasso\n",
    "oil painting by Rembrandt\n",
    "landscape art by Frederic Edwin Church\n",
    "pencil drawing by Albrecht Dürer\n",
    "```\n",
    "\n",
    "You can also combine different artists as well.\n",
    "\n",
    "To generate artistic images by category, you can add the art category in the prompt such as\n",
    "\n",
    "```\n",
    "lion on a beach, abstract\n",
    "```\n",
    "\n",
    "Some other categories include\n",
    "\n",
    "```\n",
    "oil painting\n",
    "pencil drawing\n",
    "pop art\n",
    "digital art\n",
    "anime\n",
    "cartoon\n",
    "futurism\n",
    "watercolor\n",
    "manga\n",
    "&c.\n",
    "```\n",
    "\n",
    "You can also include details such as lighting or camera lens such as\n",
    "\n",
    "```\n",
    "35mm wide lens\n",
    "85mm wide lens\n",
    "```\n",
    "\n",
    "and details about the framing\n",
    "\n",
    "```\n",
    "portrait\n",
    "landscape\n",
    "close up\n",
    "&c.\n",
    "```\n",
    "\n",
    "Note that models can generate different images even if same prompt is given multiple times. \n",
    "\n",
    "So, you can generate multiple images and select the image that suits your application best.\n",
    "\n",
    "> ☝️ For more information on Amazon Titan Image Generator prompt engineering, see [Amazon Titan Image Generator Prompt Engineering Best Practices](https://d2eo22ngex1n9g.cloudfront.net/Documentation/User+Guides/Titan/Amazon+Titan+Image+Generator+Prompt+Engineering+Guidelines.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "⚠️ ⚠️ ⚠️ Before running this notebook, make sure you've executed the [Bedrock boto3 setup notebook](../00_Intro/bedrock_boto3_setup.ipynb#Prerequisites). ⚠️ ⚠️ ⚠️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# External dependencies\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import botocore\n",
    "\n",
    "boto3_bedrock = boto3.client(\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Image\n",
    "\n",
    "In text-to-image mode, we provide a text description (prompt) of the image that **should** be generated.\n",
    "\n",
    "What if we want to ***avoid*** specific content or stylistic choices? Because image generation models are typically trained from *image descriptions*, trying to directly specify what you **don't** want in the prompt (e.g. `man without a beard`) doesn't usually work well: it would be very unusual to describe an image by what it is not!\n",
    "\n",
    "In the case of Amazon Titan Image Generator, we can specify a negative prompt to steer the model away from unwanted elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"a beautiful lake surrounded by trees with a mountain range at the distance\"\n",
    "negative_prompts = \"poorly rendered, poor background details, poorly drawn mountains, disfigured mountain features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amazon Bedrock `InvokeModel` provides access to Amazon Titan Image Generator by setting the right model ID, and returns a JSON response including a [Base64 encoded string](https://en.wikipedia.org/wiki/Base64) that represents the (PNG) image.\n",
    "\n",
    "When making an `InvokeModel` request, we need to fill the `body` field with a JSON object that varies depending on the task (`taskType`) you wish to perform viz. text to image, image variation, inpainting or outpainting. The Amazon Titan models supports the following parameters:\n",
    "* `cfgscale` - determines how much the final image reflects the prompt\n",
    "* `seed` - a number used to initialize the generation, using the same seed with the same prompt + settings combination will produce the same results\n",
    "* `numberOfImages` - the number of times the image is sampled and produced\n",
    "* `quality` - determines the output image quality (`standard` or `premium`)\n",
    "\n",
    "> ☝️ For more information on available input parameters for the model, refer to the [Amazon Bedrock User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html#model-parameters-titan-img-request-body) (Inference parameters > Amazon Titan image models > Model invocation request body fields).\n",
    "\n",
    "The cell below invokes the Amazon Titan Image Generator model through Amazon Bedrock to create an initial image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create payload\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,  # Required\n",
    "            \"negativeText\": negative_prompts,  # Optional\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,  # Range: 1 to 5\n",
    "            \"quality\": \"standard\",  # Options: standard or premium\n",
    "            \"height\": 1024,  # Supported height list in the docs\n",
    "            \"width\": 1024,  # Supported width list in the docs\n",
    "            \"cfgScale\": 7.5,  # Range: 1.0 (exclusive) to 10.0\n",
    "            \"seed\": 42,  # Range: 0 to 214783647\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "# Make model request\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body,\n",
    "    modelId=\"amazon.titan-image-generator-v1\",\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\",\n",
    ")\n",
    "\n",
    "# Process the image\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "img1_b64 = response_body[\"images\"][0]\n",
    "\n",
    "# Debug\n",
    "print(f\"Output: {img1_b64[0:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By decoding our image string and loading it with an image processing library like [Pillow](https://pillow.readthedocs.io/en/stable/), we can display and manipulate the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data/titan\", exist_ok=True)\n",
    "\n",
    "# Decode + save\n",
    "img1 = Image.open(io.BytesIO(base64.decodebytes(bytes(img1_b64, \"utf-8\"))))\n",
    "img1.save(f\"data/titan/image_1.png\")\n",
    "\n",
    "# Display\n",
    "img1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Variation\n",
    "\n",
    "Generating images from text is powerful but, in some cases, you will need many rounds of prompt refinement to get just the right image.\n",
    "\n",
    "Rather than starting from scratch, image-to-image generation lets us **modify** an existing image to make  specific changes.\n",
    "\n",
    "We'll have to pass our initial image in base64 encoding to API, so let's get that out of the way.\n",
    "\n",
    "(Feel free to use image created in the previous section or a different one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_base64(img) -> str:\n",
    "    \"\"\"Converts a PIL Image or local image file path to a base64 string\"\"\"\n",
    "    if isinstance(img, str):\n",
    "        if os.path.isfile(img):\n",
    "            print(f\"Reading image from file: {img}\")\n",
    "            with open(img, \"rb\") as f:\n",
    "                return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"File {img} does not exist\")\n",
    "    elif isinstance(img, Image.Image):\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"PNG\")\n",
    "        return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(f\"Expected str (filename) or PIL Image. Got {type(img)}\")\n",
    "\n",
    "\n",
    "img1_b64 = image_to_base64(img1)\n",
    "print(f\"Input: {img1_b64[:80]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a new prompt to guide the model when acting on the base image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "change_prompt = \"add a house on the lake shore\"\n",
    "negative_prompt = \"bad quality, low resolution, cartoon\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The existing image is then passed through to the Titan model via the `images` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Payload creation\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"IMAGE_VARIATION\",\n",
    "        \"imageVariationParams\": {\n",
    "            \"text\": change_prompt,  # Optional\n",
    "            \"negativeText\": negative_prompts,  # Optional\n",
    "            \"images\": [img1_b64],  # One image is required\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,\n",
    "            \"quality\": \"premium\",\n",
    "            \"height\": 1024,\n",
    "            \"width\": 1024,\n",
    "            \"cfgScale\": 10,\n",
    "            \"seed\": 42,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "# Model invocation\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body,\n",
    "    modelId=\"amazon.titan-image-generator-v1\",\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\",\n",
    ")\n",
    "\n",
    "# Output processing\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "img2_b64 = response_body[\"images\"][0]\n",
    "\n",
    "# Debug\n",
    "print(f\"Output: {img2_b64[0:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data/titan\", exist_ok=True)\n",
    "\n",
    "# Decode + save\n",
    "img2 = Image.open(io.BytesIO(base64.decodebytes(bytes(img2_b64, \"utf-8\"))))\n",
    "img2.save(\"data/titan/image_2.png\")\n",
    "\n",
    "# Display\n",
    "img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inpainting\n",
    "\n",
    "Another way to modify images is by using **inpainting**.\n",
    "\n",
    "Inpainting refers to the process of replacing a portion of an image with another image based on a textual prompt.\n",
    "\n",
    "By providing a mask image that outlines the portion to be replaced, a textual prompt, and the original image, the model can produce a new image that replaces the masked area with the object, subject, or environment described in the textual prompt.\n",
    "\n",
    "Let's start by creating a function that generates a mask from the original image and a set of box coordinates `(top, left, right, bottom)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "\n",
    "\n",
    "def inpaint_mask(img, box):\n",
    "    \"\"\"Generates a segmentation mask for inpainting\"\"\"\n",
    "    img_size = img.size\n",
    "    assert len(box) == 4  # (left, top, right, bottom)\n",
    "    assert box[0] < box[2]\n",
    "    assert box[1] < box[3]\n",
    "    return ImageOps.expand(\n",
    "        Image.new(mode=\"RGB\", size=(box[2] - box[0], box[3] - box[1]), color=\"black\"),\n",
    "        border=(box[0], box[1], img_size[0] - box[2], img_size[1] - box[3]),\n",
    "        fill=\"white\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove a single patch at the center of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img2_size = img2.size\n",
    "box = (\n",
    "    (img2_size[0] - 300) // 2,\n",
    "    img2_size[1] - 300,\n",
    "    (img2_size[0] + 300) // 2,\n",
    "    img2_size[1] - 200,\n",
    ")\n",
    "\n",
    "# Mask\n",
    "mask = inpaint_mask(img2, box)\n",
    "\n",
    "# Debug\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define what we want to change in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inpaint_prompt = \"add a fishing boat\"\n",
    "negative_prompts = \"bad quality, low res\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to what we did before, we will the pass the previously generated image through to the Stable Diffusion model via the `image` parameter.\n",
    "\n",
    "This time, we will also specify the `maskImage` parameter to pass the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Payload creation\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"INPAINTING\",\n",
    "        \"inPaintingParams\": {\n",
    "            \"text\": inpaint_prompt,  # Optional\n",
    "            \"negativeText\": negative_prompts,  # Optional\n",
    "            \"image\": image_to_base64(img2),  # Required\n",
    "            # \"maskPrompt\": \"sky\",               # One of \"maskImage\" or \"maskPrompt\" is required\n",
    "            \"maskImage\": image_to_base64(\n",
    "                mask\n",
    "            ),  # Input maskImage based on the values 0 (black) or 255 (white) only\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,\n",
    "            \"quality\": \"premium\",\n",
    "            \"height\": 1024,\n",
    "            \"width\": 1024,\n",
    "            \"cfgScale\": 7.5,\n",
    "            \"seed\": 42,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "# Model invocation\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body,\n",
    "    modelId=\"amazon.titan-image-generator-v1\",\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\",\n",
    ")\n",
    "\n",
    "# Output processing\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "img3_b64 = response_body[\"images\"][0]\n",
    "print(f\"Output: {img3_b64[0:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets show the image we just modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data/titan\", exist_ok=True)\n",
    "inpaint = Image.open(io.BytesIO(base64.decodebytes(bytes(img3_b64, \"utf-8\"))))\n",
    "inpaint.save(\"data/titan/inpaint.png\")\n",
    "inpaint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from using \"maskImage\", we can use \"maskPrompt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inpaint_prompt = \"add a roller coaster\"\n",
    "negative_prompts = \"bad quality, low res\"\n",
    "mask_prompt = \"house\"  # replace house in img1 with a roller coaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Payload creation\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"INPAINTING\",\n",
    "        \"inPaintingParams\": {\n",
    "            \"text\": inpaint_prompt,  # Optional\n",
    "            # \"negativeText\": negative_prompts,    # Optional\n",
    "            \"image\": image_to_base64(img1),  # Required\n",
    "            \"maskPrompt\": mask_prompt,  # One of \"maskImage\" or \"maskPrompt\" is required\n",
    "            # \"maskImage\": image_to_base64(mask),  # Input maskImage based on the values 0 (black) or 255 (white) only\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,\n",
    "            \"quality\": \"premium\",\n",
    "            \"height\": 1024,\n",
    "            \"width\": 1024,\n",
    "            \"cfgScale\": 7.5,\n",
    "            \"seed\": 42,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "# Model invocation\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body,\n",
    "    modelId=\"amazon.titan-image-generator-v1\",\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\",\n",
    ")\n",
    "\n",
    "# Output processing\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "img4_b64 = response_body[\"images\"][0]\n",
    "print(f\"Output: {img4_b64[0:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data/titan\", exist_ok=True)\n",
    "inpaint2 = Image.open(io.BytesIO(base64.decodebytes(bytes(img4_b64, \"utf-8\"))))\n",
    "inpaint2.save(\"data/titan/inpaint2.png\")\n",
    "inpaint2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outpainting\n",
    "\n",
    "In this final section, we are going to *extend* the image.\n",
    "\n",
    "This process, known as **outpainting**, involves generating new pixels that *seamlessly* extend an image's existing boundaries.\n",
    "\n",
    "We can do this by providing the original image and a segmentation mask, which can either be an image or a prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a function that takes in the original image and the target size `(width, height)` and returns a mask image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def outpaint_mask(img, new_size):\n",
    "    \"\"\"Generates a segmentation mask for outpainting\"\"\"\n",
    "    # Image size must be a multiple of 64\n",
    "    old_size = img.size\n",
    "    assert len(new_size) == 2\n",
    "    assert new_size[0] >= old_size[0]\n",
    "    assert new_size[1] >= old_size[1]\n",
    "    assert new_size[0] % 64 == 0\n",
    "    assert new_size[1] % 64 == 0\n",
    "    # Create a mask and expand it\n",
    "    border = ((new_size[0] - old_size[0]) // 2, (new_size[1] - old_size[1]) // 2)\n",
    "    return ImageOps.expand(\n",
    "        Image.new(mode=\"RGB\", size=img.size, color=\"black\"), border=border, fill=\"white\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to crop the image created in the **Image Inpainting** section and then expand the cropped area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inpaint_crop = ImageOps.crop(inpaint, border=(300, 400, 300, 200))\n",
    "print(f\"Crop size: {inpaint_crop.size}\")\n",
    "inpaint_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define border\n",
    "old_size = inpaint_crop.size\n",
    "new_size = (1024, 1024)\n",
    "border = ((new_size[0] - old_size[0]) // 2, (new_size[1] - old_size[1]) // 2)\n",
    "\n",
    "# Generate a mask\n",
    "mask = outpaint_mask(inpaint_crop, new_size)\n",
    "\n",
    "# Debug\n",
    "print(f\"Original Image: {old_size}\")\n",
    "print(f\"Outpaint Mask: {mask.size}\")\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outpaint_prompt = \"add some trees and houses near the lake\"\n",
    "# negative_prompt = \"bad quality, low res\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add everything to our payload and make the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Payload creation\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"OUTPAINTING\",\n",
    "        \"outPaintingParams\": {\n",
    "            \"text\": outpaint_prompt,\n",
    "            # \"negativeText\": negative_prompts,\n",
    "            \"image\": image_to_base64(\n",
    "                ImageOps.expand(inpaint_crop, border=border, fill=\"white\")\n",
    "            ),\n",
    "            # \"maskPrompt\": mask_prompt,\n",
    "            \"maskImage\": image_to_base64(mask),\n",
    "            \"outPaintingMode\": \"DEFAULT\",\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,\n",
    "            \"quality\": \"standard\",\n",
    "            \"cfgScale\": 1.5,\n",
    "            \"seed\": 321,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "# Model invocation\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body,\n",
    "    modelId=\"amazon.titan-image-generator-v1\",\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\",\n",
    ")\n",
    "\n",
    "# Output processing\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "img_5_b64_str = response_body[\"images\"][0]\n",
    "print(f\"Output: {img_5_b64_str[0:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it finishes, we can display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Decode + save\n",
    "outpaint = Image.open(io.BytesIO(base64.decodebytes(bytes(img_5_b64_str, \"utf-8\"))))\n",
    "outpaint.save(\"data/titan/outpaint.png\")\n",
    "\n",
    "# Display\n",
    "outpaint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from using \"maskImage\", we can use \"maskPrompt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outpaint_prompt = \"add some trees and houses near the lake\"\n",
    "# negative_prompt = \"bad quality, low res\"\n",
    "\n",
    "# try different mask_prompt to see the difference in generated images\n",
    "mask_prompt = \"lake\"\n",
    "# mask_prompt = \"forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Payload creation\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"OUTPAINTING\",\n",
    "        \"outPaintingParams\": {\n",
    "            \"text\": outpaint_prompt,\n",
    "            # \"negativeText\": negative_prompts,\n",
    "            \"image\": image_to_base64(\n",
    "                ImageOps.expand(inpaint_crop, border=border, fill=\"white\")\n",
    "            ),\n",
    "            # \"image\": image_to_base64(inpaint_crop),\n",
    "            \"maskPrompt\": mask_prompt,\n",
    "            # \"maskImage\": image_to_base64(mask),\n",
    "            \"outPaintingMode\": \"DEFAULT\",\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,\n",
    "            \"quality\": \"standard\",\n",
    "            \"cfgScale\": 1.5,\n",
    "            \"seed\": 321,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "# Model invocation\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body,\n",
    "    modelId=\"amazon.titan-image-generator-v1\",\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\",\n",
    ")\n",
    "\n",
    "# Output processing\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "img_6_b64_str = response_body[\"images\"][0]\n",
    "print(f\"Output: {img_6_b64_str[0:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Decode + save\n",
    "outpaint2 = Image.open(io.BytesIO(base64.decodebytes(bytes(img_6_b64_str, \"utf-8\"))))\n",
    "outpaint2.save(\"data/titan/outpaint2.png\")\n",
    "\n",
    "# Display\n",
    "outpaint2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we demonstrated how to generate new images from text and transform existing images with text instructions using [Amazon Titan Image Generator](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-image-models.html) on [Amazon Bedrock](https://aws.amazon.com/bedrock/).\n",
    "\n",
    "Through the Bedrock API, we can provide a range of parameters to influence image generation (`text`, `negativeText`, `maskImage`, &c.)\n",
    "\n",
    "One key point to note when using Amazon Bedrock is that the output image data is returned as a [Base64 encoded string](https://en.wikipedia.org/wiki/Base64) within the JSON API response. You can use the Python built-in [`base64` library](https://docs.python.org/3/library/base64.html) to decode this image data and then save a `.png` file. We also showed that image processing libraries like [Pillow](https://pillow.readthedocs.io/en/stable/) can be used to load (and edit) images within Python.\n",
    "\n",
    "From here, you can explore more advanced image generation options or combine GenAI with traditional image processing tools to build the best creative workflow for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 50,
           "length": 1,
           "op": "removerange"
          },
          {
           "key": 52,
           "op": "addrange",
           "valuelist": "a"
          },
          {
           "key": 55,
           "op": "addrange",
           "valuelist": "1:0813"
          },
          {
           "key": 56,
           "op": "addrange",
           "valuelist": "5"
          },
          {
           "key": 56,
           "length": 2,
           "op": "removerange"
          },
          {
           "key": 59,
           "op": "addrange",
           "valuelist": "90"
          },
          {
           "key": 59,
           "length": 2,
           "op": "removerange"
          },
          {
           "key": 62,
           "op": "addrange",
           "valuelist": "99"
          },
          {
           "key": 62,
           "length": 7,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  },
  "vscode": {
   "interpreter": {
    "hash": "00878cbed564b904a98b4a19808853cb6b9988746b881ea025a8408713879bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
